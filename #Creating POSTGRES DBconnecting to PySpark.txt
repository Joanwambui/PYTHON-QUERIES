#Creating POSTGRES DB
CREATE DATABASE etl_pipeline;
#Connecting to the database
\c etl_pipeline;
etl_pipeline= #CREATE TABLE movies (
id SERIAL PRIMARY KEY,
name VARCHAR(255)
description VARCHAR(255),
category VARCHAR(255)
);
#Copy rows from CSV file to the table movies already created
\copy movies FROM '/Users/harshit/lil/lil/-data_engineering/movies.csv' DELIMETER ',' CSV HEADER;

select * from movies

Connecting to Pyspark
import pyspark
#create spark session

spark = pyspark.sql.SparkSession\
.builder \
.appName("Python Spark SQL basic example") \
.config('spark.driver.extraClassPath", "/Users/harshit/Downloads/postgresql-42.2.18.jar") \
.getOrCreate()


movies_df = spark.read \
.format("jdbc") \
.option("url", "jdbc:postgresql://localhost:5432/etl_pipeline") \
.option("dbtable", "movies") \
.option("user", "harshit")\
.option("password", "doll") \
.option("driver", "org.postgresql.Driver") \
.load()


##print the movies_df



