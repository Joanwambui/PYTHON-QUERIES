# Assuming 'df' is your DataFrame created earlier
average_prices_by_category = df.groupby('category')['price'].mean()

# Display the result
print(average_prices_by_category)

SELECT AVG(price), category
FROM Listings
GROUP BY category



---------------------------------------------------------------------------------------------------------------------------------
average_prices_by_city = df.groupby('city')['price'].mean()

# 3. Find the city with the lowest average price
city_with_lowest_avg_price = average_prices_by_city.idxmin()
lowest_avg_price_value     = average_prices_by_city.min()

# 4. Print the results in table form
print("city\tAVG(price)")
print(f"{city_with_lowest_avg_price}\t{int(lowest_avg_price_value)}")

 SELECT city, AVG(price)
FROM Listings
GROUP BY city
ORDER BY AVG(price) ASC
LIMIT 1


--------------------------------------------------------------------------------------------------------------------------------------
SELECT
  department_id,
  FLOOR(AVG(satisfaction_score)) AS avg_satisfaction_score
FROM employee_satisfaction
GROUP BY department_id;


# 1. Calculate the mean satisfaction score per department
avg_scores = df.groupby('department_id')['satisfaction_score'].mean()

# 2. Round down to the nearest whole number
avg_scores = np.floor(avg_scores).astype(int)



----------------------------------------------------------------------------------------------------------------------------------------------------
import pandas as pd
import numpy as np

# Example: load from CSV (or replace with your own data source)
# df = pd.read_csv("employee_satisfaction.csv")

# Ensure your DataFrame has the columns: 
#   - satisfaction_score (numeric)
#   - job_category_id
#   - department_id

# 1. Group by the two IDs and compute the average
grouped = (
    df
    .groupby(['job_category_id', 'department_id'], as_index=False)
    .agg(avg_score=('satisfaction_score', 'mean'))
)

# 2. Apply ceiling and floor
grouped['Ceil_Avg_Satisfaction']  = np.ceil(grouped['avg_score'])
grouped['Floor_Avg_Satisfaction'] = np.floor(grouped['avg_score'])

# 3. (Optional) Reorder or drop the intermediate avg_score column
result = grouped[
    ['Ceil_Avg_Satisfaction', 'Floor_Avg_Satisfaction', 
     'job_category_id', 'department_id']
]

print(result)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT campaign_id, SUM(conversions)
FROM ad_campaigns
WHERE start_date BETWEEN '01/04/2024' AND '30/04/2024'
GROUP BY campaign_id
ORDER BY SUM(conversions) DESC
LIMIT 5

top5 = (
    df[df["start_date"].between("2024-04-01", "2024-04-30")]
    .groupby("campaign_id", as_index=False)["conversions"]
    .sum()
    .rename(columns={"conversions": "total_conversions"})
    .sort_values("total_conversions", ascending=False)
    .head(5)
)

print(top5)

---------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT DISTINCT ad_type
FROM ad_campaigns
WHERE conversions > 100
  AND start_date >= '2024-05-01'
  AND start_date <  '2024-06-01';


import pandas as pd

# 1. Load the CSV and parse dates
df = pd.read_csv("ad_campaigns.csv", parse_dates=["start_date"])

# 2. Build a mask for May 2024 and conversions > 100
mask = (
    (df["start_date"] >= "2024-05-01") &
    (df["start_date"] <  "2024-06-01") &
    (df["conversions"] > 100)
)

# 3. Pull out the ad_type column, drop duplicates, and reset the index
result = (
    df.loc[mask, ["ad_type"]]
      .drop_duplicates()
      .reset_index(drop=True)
)

# 4. Display
print(result)


import pandas as pd

df = pd.read_csv("ad_campaigns.csv", parse_dates=["start_date"])

unique_ad_types = (
    df[
        df["start_date"].between("2024-05-01", "2024-05-31") &
        (df["conversions"] > 100)
    ]
    .loc[:, ["ad_type"]]
    .drop_duplicates()
    .reset_index(drop=True)
)

print(unique_ad_types)


-----------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT campaign_name , start_date, revenue
FROM ad_campaigns
WHERE start_date >= '2024-06-01'
AND start_date < '2024-07-01'
AND revenue = 0


import pandas as pd

# ensure your dates are datetimes
df["start_date"] = pd.to_datetime(df["start_date"])

# filter for June 2024 and zero revenue
revenue_zero = (
    df.loc[
        (df["start_date"] >= "2024-06-01") &
        (df["start_date"] <  "2024-07-01") &
        (df["revenue"] == 0),
        ["campaign_name", "start_date", "revenue"]
    ]
    .reset_index(drop=True)
)

print(revenue_zero)

---------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT COUNT (DISTINCT artist_id)
FROM fct_artist_recommendations
WHERE recommendation_date >= '01/04/2024' AND recommendation_date < '01/05/2024'

count = (
    df.loc[
        (df["recommendation_date"] >= "2024-04-01") &
        (df["recommendation_date"] <  "2024-05-01"),
        "artist_id"
    ]
    .nunique())
print(count)

------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT COUNT(recommendation_id)
FROM fct_artist_recommendations
WHERE recommendation_date >= '01/05/2024' AND recommendation_date < '01/06/2024'
AND is_new_artist = 1


count = (
df.loc[
(df["recommendation_date"] >= "2024-05-01") &
(df["recommendation_date"] < "2024-06-01") &
(df["is_new_artist"] == 1), "recommendation_id"].count())
print(count)


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT 
  strftime('%m', recommendation_date) AS month,
  COUNT(DISTINCT artist_id) AS new_artist_count
FROM fct_artist_recommendations
WHERE 
  is_new_artist = 1
  AND recommendation_date >= '2024-04-01'
  AND recommendation_date < '2024-07-01'
GROUP BY month
ORDER BY month;



import pandas as pd

# Ensure recommendation_date is in datetime format
df["recommendation_date"] = pd.to_datetime(df["recommendation_date"])

# Filter for Q2 2024 and only new artists
filtered = df[
    (df["recommendation_date"] >= "2024-04-01") &
    (df["recommendation_date"] < "2024-07-01") &
    (df["is_new_artist"] == 1)
].copy()

# Extract month for grouping
filtered["month"] = filtered["recommendation_date"].dt.strftime("%m")

# Count distinct artist_id per month
result = (
    filtered.groupby("month", as_index=False)["artist_id"]
    .nunique()
    .rename(columns={"artist_id": "new_artist_count"})
    .sort_values("month")
)

print(result)

--------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT MIN(response_time_hours)
FROM fct_guest_inquiries
WHERE inquiry_date BETWEEN '2024-01-01' AND '2024-01-31'

filtered = df[
    (df["inquiry_date"] >= "2024-01-01") &
    (df["inquiry_date"] < "2024-02-01")
].copy()

result = filtered["response_time_hours"].min()
