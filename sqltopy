# Assuming 'df' is your DataFrame created earlier
average_prices_by_category = df.groupby('category')['price'].mean()

# Display the result
print(average_prices_by_category)

SELECT AVG(price), category
FROM Listings
GROUP BY category


---------------------------------------------------------------------------------------------------------------------------------
average_prices_by_city = df.groupby('city')['price'].mean()

# 3. Find the city with the lowest average price
city_with_lowest_avg_price = average_prices_by_city.idxmin()
lowest_avg_price_value     = average_prices_by_city.min()

# 4. Print the results in table form
print("city\tAVG(price)")
print(f"{city_with_lowest_avg_price}\t{int(lowest_avg_price_value)}")

 SELECT city, AVG(price)
FROM Listings
GROUP BY city
ORDER BY AVG(price) ASC
LIMIT 1


--------------------------------------------------------------------------------------------------------------------------------------
SELECT
  department_id,
  FLOOR(AVG(satisfaction_score)) AS avg_satisfaction_score
FROM employee_satisfaction
GROUP BY department_id;


# 1. Calculate the mean satisfaction score per department
avg_scores = df.groupby('department_id')['satisfaction_score'].mean()

# 2. Round down to the nearest whole number
avg_scores = np.floor(avg_scores).astype(int)



----------------------------------------------------------------------------------------------------------------------------------------------------
import pandas as pd
import numpy as np

# Example: load from CSV (or replace with your own data source)
# df = pd.read_csv("employee_satisfaction.csv")

# Ensure your DataFrame has the columns: 
#   - satisfaction_score (numeric)
#   - job_category_id
#   - department_id

# 1. Group by the two IDs and compute the average
grouped = (
    df
    .groupby(['job_category_id', 'department_id'], as_index=False)
    .agg(avg_score=('satisfaction_score', 'mean'))
)

# 2. Apply ceiling and floor
grouped['Ceil_Avg_Satisfaction']  = np.ceil(grouped['avg_score'])
grouped['Floor_Avg_Satisfaction'] = np.floor(grouped['avg_score'])

# 3. (Optional) Reorder or drop the intermediate avg_score column
result = grouped[
    ['Ceil_Avg_Satisfaction', 'Floor_Avg_Satisfaction', 
     'job_category_id', 'department_id']
]

print(result)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT campaign_id, SUM(conversions)
FROM ad_campaigns
WHERE start_date BETWEEN '01/04/2024' AND '30/04/2024'
GROUP BY campaign_id
ORDER BY SUM(conversions) DESC
LIMIT 5

top5 = (
    df[df["start_date"].between("2024-04-01", "2024-04-30")]
    .groupby("campaign_id", as_index=False)["conversions"]
    .sum()
    .rename(columns={"conversions": "total_conversions"})
    .sort_values("total_conversions", ascending=False)
    .head(5)
)

print(top5)

---------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT DISTINCT ad_type
FROM ad_campaigns
WHERE conversions > 100
  AND start_date >= '2024-05-01'
  AND start_date <  '2024-06-01';


import pandas as pd

# 1. Load the CSV and parse dates
df = pd.read_csv("ad_campaigns.csv", parse_dates=["start_date"])

# 2. Build a mask for May 2024 and conversions > 100
mask = (
    (df["start_date"] >= "2024-05-01") &
    (df["start_date"] <  "2024-06-01") &
    (df["conversions"] > 100)
)

# 3. Pull out the ad_type column, drop duplicates, and reset the index
result = (
    df.loc[mask, ["ad_type"]]
      .drop_duplicates()
      .reset_index(drop=True)
)

# 4. Display
print(result)


import pandas as pd

df = pd.read_csv("ad_campaigns.csv", parse_dates=["start_date"])

unique_ad_types = (
    df[
        df["start_date"].between("2024-05-01", "2024-05-31") &
        (df["conversions"] > 100)
    ]
    .loc[:, ["ad_type"]]
    .drop_duplicates()
    .reset_index(drop=True)
)

print(unique_ad_types)


-----------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT campaign_name , start_date, revenue
FROM ad_campaigns
WHERE start_date >= '2024-06-01'
AND start_date < '2024-07-01'
AND revenue = 0


import pandas as pd

# ensure your dates are datetimes
df["start_date"] = pd.to_datetime(df["start_date"])

# filter for June 2024 and zero revenue
revenue_zero = (
    df.loc[
        (df["start_date"] >= "2024-06-01") &
        (df["start_date"] <  "2024-07-01") &
        (df["revenue"] == 0),
        ["campaign_name", "start_date", "revenue"]
    ]
    .reset_index(drop=True)
)

print(revenue_zero)

---------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT COUNT (DISTINCT artist_id)
FROM fct_artist_recommendations
WHERE recommendation_date >= '01/04/2024' AND recommendation_date < '01/05/2024'

count = (
    df.loc[
        (df["recommendation_date"] >= "2024-04-01") &
        (df["recommendation_date"] <  "2024-05-01"),
        "artist_id"
    ]
    .nunique())
print(count)

------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT COUNT(recommendation_id)
FROM fct_artist_recommendations
WHERE recommendation_date >= '01/05/2024' AND recommendation_date < '01/06/2024'
AND is_new_artist = 1


count = (
df.loc[
(df["recommendation_date"] >= "2024-05-01") &
(df["recommendation_date"] < "2024-06-01") &
(df["is_new_artist"] == 1), "recommendation_id"].count())
print(count)


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT 
  strftime('%m', recommendation_date) AS month,
  COUNT(DISTINCT artist_id) AS new_artist_count
FROM fct_artist_recommendations
WHERE 
  is_new_artist = 1
  AND recommendation_date >= '2024-04-01'
  AND recommendation_date < '2024-07-01'
GROUP BY month
ORDER BY month;



import pandas as pd

# Ensure recommendation_date is in datetime format
df["recommendation_date"] = pd.to_datetime(df["recommendation_date"])

# Filter for Q2 2024 and only new artists
filtered = df[
    (df["recommendation_date"] >= "2024-04-01") &
    (df["recommendation_date"] < "2024-07-01") &
    (df["is_new_artist"] == 1)
].copy()

# Extract month for grouping
filtered["month"] = filtered["recommendation_date"].dt.strftime("%m")

# Count distinct artist_id per month
result = (
    filtered.groupby("month", as_index=False)["artist_id"]
    .nunique()
    .rename(columns={"artist_id": "new_artist_count"})
    .sort_values("month")
)

print(result)

--------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT MIN(response_time_hours)
FROM fct_guest_inquiries
WHERE inquiry_date BETWEEN '2024-01-01' AND '2024-01-31'

filtered = df[
    (df["inquiry_date"] >= "2024-01-01") &
    (df["inquiry_date"] < "2024-02-01")
].copy()

result = filtered["response_time_hours"].min()


----------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT 
  ROUND(AVG(response_time_hours)) AS avg_response_time_hours
FROM 
  fct_guest_inquiries
WHERE 
  inquiry_date >= '2024-01-01' 
  AND inquiry_date < '2024-02-01';


filtered = df[
    (df["inquiry_date"] >= "2024-01-01") &
    (df["inquiry_date"] < "2024-02-01")
].copy()

result = round(filtered["response_time_hours"].mean())
print(result)


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT inquiry_id, response_time_hours
FROM fct_guest_inquiries
WHERE inquiry_date >= '16-01-2024' AND inquiry_date <= '31-01-2024'
AND response_time_hours > 2

# Ensure inquiry_date is in datetime format if not already
df["inquiry_date"] = pd.to_datetime(df["inquiry_date"])

filtered = df[
    (df["inquiry_date"] >= "2024-01-16") &
    (df["inquiry_date"] <= "2024-01-31") &
    (df["response_time_hours"] > 2)
].copy()

result = filtered[["inquiry_id", "response_time_hours"]]
print(result)

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT COUNT(label_id), user_id
FROM email_labels
GROUP BY user_id

result = df.groupby("user_id")["label_id"].count()
print(result)



------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT
  label_id,
  COUNT(email_id) AS totalcount
FROM emails e
GROUP BY label_id
HAVING COUNT(email_id) > 5;

# step 1: get total counts per label
totals = (
    df
    .groupby("label_id")["email_id"]
    .count()
    .reset_index(name="totalcount")
)

	label_id	totalcount
1	B	6
2	C	8
4	E	10



# step 2: keep only those above 5
filtered_totals = totals[totals["totalcount"] > 5]

print(filtered_totals)

-----------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT
  el.label_id,
  COUNT(e.email_id) AS email_count
FROM email_labels AS el
LEFT JOIN emails AS e
  ON el.label_id = e.label_id
WHERE el.created_date >= '2024-10-01'
  AND el.created_date <  '2024-11-01'
GROUP BY el.label_id
ORDER BY el.label_id;

import pandas as pd

# 1. Make sure your two DataFrames exist:
#    df_labels: columns → ['label_id', 'user_id', 'created_date', …]
#    df_emails: columns → ['email_id', 'label_id', …]

# 2. Convert created_date to datetime
df_labels['created_date'] = pd.to_datetime(df_labels['created_date'])

# 3. Filter labels created in October 2024
oct_labels = df_labels[
    (df_labels['created_date'] >= '2024-10-01') &
    (df_labels['created_date'] <  '2024-11-01')
].copy()

# 4. LEFT-join emails onto those labels
merged = oct_labels.merge(df_emails, on='label_id', how='left')

# 5. Group and count non-null email_id per label
email_counts = (
    merged
    .groupby('label_id')['email_id']
    .count()                        # only counts non-null entries
    .reset_index(name='email_count')
    .sort_values('label_id')
)

print(email_counts)


-----------------------------------------------------------------------------------------------------------------------------------------------------
SELECT 
  COUNT(DISTINCT customer_id) AS unique_premium_customers
FROM fct_transactions
WHERE 
  service_tier_code LIKE 'PREM%' 
  AND transaction_date >= '2024-04-01'
  AND transaction_date  < '2024-05-01';

import pandas as pd

# ensure your DataFrame df is loaded and has the right dtypes
df['transaction_date'] = pd.to_datetime(df['transaction_date'])

# filter for April 2024 and service tiers starting with "PREM"
filtered = df[
    (df['transaction_date'] >= '2024-04-01') &
    (df['transaction_date'] <  '2024-05-01') &
    (df['service_tier_code'].str.startswith('PREM'))
]

# count distinct customer_id
unique_premium_customers = filtered['customer_id'].nunique()

print(unique_premium_customers)

-----------------------------------------------------------------------------------------------------------------------------------------------------
WITH tier_counts AS (
  SELECT
    service_tier_code,
    COUNT(*) AS transaction_count
  FROM fct_transactions
  WHERE 
    transaction_date >= '2024-05-01'
    AND transaction_date  < '2024-06-01'
  GROUP BY service_tier_code
)
SELECT
  service_tier_code,
  transaction_count,
  RANK() OVER (ORDER BY transaction_count DESC) AS usage_rank
FROM tier_counts
ORDER BY usage_rank;



df['transaction_date'] = pd.to_datetime(df['transaction_date'])

tier_counts = (
    df[(df['transaction_date'] >= '2024-05-01') & (df['transaction_date'] < '2024-06-01')]
    .groupby('service_tier_code')
    .size()
    .reset_index(name='transaction_count')
    .assign(usage_rank=lambda x: x['transaction_count'].rank(method='dense', ascending=False).astype(int))
    .sort_values('usage_rank')
)

print(tier_counts)


-------------------------------------------------------------------------------------------------------------------------------------------------------------
SELECT
  service_tier_code,
  COUNT(transaction_id) AS transactions
FROM fct_transactions
WHERE transaction_date >= '2024-06-01'
  AND transaction_date < '2024-07-01'
GROUP BY service_tier_code
ORDER BY transactions DESC
LIMIT 3;


import pandas as pd

# Ensure 'transaction_date' is datetime
df['transaction_date'] = pd.to_datetime(df['transaction_date'])

# Filter transactions for June 2024
filtered = df[
    (df['transaction_date'] >= '2024-06-01') &
    (df['transaction_date'] <  '2024-07-01') 
]

# Group by service_tier_code, count transaction_id, sort descending, and get top 3
result = (
    filtered.groupby('service_tier_code')['transaction_id']
    .count()
    .reset_index(name='transactions')
    .sort_values('transactions', ascending=False)
    .head(3)
)

print(result)

-------------------------------------------------------------------------------------------------------------------------------------------
SELECT key_message, brand_score
FROM brand_score_metrics
WHERE metric_date >= '2024-10-01' AND 
metric_date < '2025-01-01'


filtered = df[
    (df['metric_date'] >= '2024-10-01') & 
    (df['metric_date'] < '2025-01-01')
]

result = filtered[['key_message', 'brand_score']]

------------------------------------------------------------------------------------------------------------------------------------------------
SELECT key_message, brand_score
FROM brand_score_metrics
WHERE segment_id = 2 AND 
metric_date >= '2024-10-01' AND 
metric_date < '2025-01-01' AND
brand_score >= 90


filtered = df[
    (df['metric_date'] >= '2024-10-01') & 
    (df['metric_date'] < '2025-01-01') &
(df['segment_id'] == 2) & (df['brand_score'] >=90)
]

result = filtered[['key_message', 'brand_score']]



----------------------------------------------------------------------------------------------------------------------------------------------------
#Most recent date should be descending
SELECT key_message,brand_score
FROM brand_score_metrics
WHERE segment_id= 3 AND brand_score > 80
ORDER BY metric_date DESC
LIMIT 5


filtered = (df['segment_id'] == 3 ) & (df['brand_score'] > 80) 
result = filtered [['key_message', 'brand_score']].sort_values('metric_date', ascending=False).head(5) 


result = (
    df[(df['segment_id'] == 3) & (df['brand_score'] > 80)]
    [['key_message', 'brand_score', 'metric_date']]
    .sort_values('metric_date', ascending=False)
    .head(5)
    [['key_message', 'brand_score']]
)


-------------------------------------------------------------------------------------------------------------------------------
SELECT
  COUNT(DISTINCT viewer_id) AS unique_october_viewers
FROM
  viewer_interactions
WHERE
  interaction_date >= '2024-10-01'
  AND interaction_date <  '2024-11-01';


filtered = df[
    (df['metric_date'] >= '2024-10-01') & 
    (df['metric_date'] < '2025-01-01') 

result = filtered['viewer_id'].nunique()
print(result)


-------------------------------------------------------------------------------------------------------------------------------
SELECT viewer_id
FROM viewer_interactions
WHERE interaction_type = 'pause' AND
interaction_date >= '2024-12-01'
    AND interaction_date  < '2025-01-01'



filtered = df[
(df['interaction_date'] >= '2024-12-01') &
(df['interaction_date'] < '2025-01-01')
& df['interaction_type'] == 'pause']

result = filtered['viewer_id']
print(result)

----------------------------------------------------------------------------------------------------------------------------------

WITH jan_loans AS (
  SELECT DISTINCT business_id
  FROM fct_loans
  WHERE loan_issued_date >= '2024-01-01'
    AND loan_issued_date < '2024-02-01'
)

SELECT
  AVG(CASE WHEN jl.business_id IS NOT NULL THEN db.monthly_revenue END) AS avg_revenue_received_loan,
  AVG(CASE WHEN jl.business_id IS NULL THEN db.monthly_revenue END) AS avg_revenue_not_received_loan
FROM dim_businesses db
LEFT JOIN jan_loans jl
  ON db.business_id = jl.business_id
WHERE db.business_size = 'small';



import pandas as pd

# Step 1: Filter January 2024 loans
jan_loans = fct_loans[
    (fct_loans['loan_issued_date'] >= '2024-01-01') &
    (fct_loans['loan_issued_date'] < '2024-02-01')
][['business_id']].drop_duplicates()

# Step 2: LEFT JOIN with dim_businesses
merged = dim_businesses.merge(jan_loans, on='business_id', how='left', indicator=True)

# Step 3: Filter for small businesses only
small_businesses = merged[merged['business_size'] == 'small']

# Step 4: Calculate the two averages
avg_revenue_received_loan = small_businesses[small_businesses['_merge'] == 'both']['monthly_revenue'].mean()
avg_revenue_not_received_loan = small_businesses[small_businesses['_merge'] == 'left_only']['monthly_revenue'].mean()

# Step 5: Print results
print(f"Average monthly revenue for small businesses that received a loan in Jan 2024: {avg_revenue_received_loan:.2f}")
print(f"Average monthly revenue for small businesses that did NOT receive a loan in Jan 2024: {avg_revenue_not_received_loan:.2f}")


-------------------------------------------------------------------------------------------------------------------------------------------------
SELECT
  COUNT(CASE WHEN f.loan_repaid = 1 THEN 1 END) * 100.0 / COUNT(*) AS repayment_percentage
FROM fct_loans f
JOIN dim_businesses d ON f.business_id = d.business_id
WHERE f.loan_issued_date >= '2024-01-01'
  AND f.loan_issued_date < '2024-02-01'
  AND d.business_size = 'small';


import pandas as pd

# Step 1: Filter fct_loans for January 2024
filtered = fct_loans[
    (fct_loans['loan_issued_date'] >= '2024-01-01') &
    (fct_loans['loan_issued_date'] < '2024-02-01')
]

# Step 2: INNER JOIN with dim_businesses on business_id
merged = pd.merge(
    filtered,
    dim_businesses,
    on='business_id',
    how='inner'
)

# Step 3: Filter for small businesses
small_businesses = merged[merged['business_size'] == 'small']

# Step 4: Calculate repayment percentage
repaid_count = (small_businesses['loan_repaid'] == 1).sum()
total_loans = len(small_businesses)

repayment_percentage = (repaid_count / total_loans) * 100 if total_loans > 0 else 0

print(f"Repayment Percentage: {repayment_percentage:.2f}%")


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

SELECT
  CASE
    WHEN d.revenue_variability < 0.1 THEN 'Low'
    WHEN d.revenue_variability BETWEEN 0.1 AND 0.3 THEN 'Medium'
    WHEN d.revenue_variability > 0.3 THEN 'High'
  END AS variability_category,
  COUNT(CASE WHEN f.loan_repaid = 1 THEN 1 END) * 100.0 / COUNT(*) AS repayment_percentage
FROM fct_loans f
JOIN dim_businesses d ON f.business_id = d.business_id
WHERE f.loan_issued_date >= '2024-01-01'
  AND f.loan_issued_date < '2024-02-01'
  AND d.business_size = 'small'
GROUP BY variability_category;


--------------------------------------------------------------------------------------------------------------------------------------------
SELECT 
  COUNT(CASE WHEN pickup_count >= 2 THEN 1 END) * 100.0 / COUNT(*) AS percentage_with_multiple_pickups
FROM fct_delivery_routes
WHERE route_date >= '2024-10-01' 
  AND route_date < '2025-01-01';


filtered = fct_loans[
    (fct_loans['loan_issued_date'] >= '2024-10-01') &
    (fct_loans['loan_issued_date'] < '2025-01-01')

countpickup = (filtered['pickup_count'] == 1).sum()
totalcount = len(filtered)
pickup_percentage = (countpickup/totalcount)*100 if totalcount > 0 else 0

------------------------------------------------------------------------------------------------------------------------------------------------
SELECT 
  CASE 
    WHEN pickup_count = 2 THEN 'Only_two'
    WHEN pickup_count >= 3 THEN 'Three_or_more'
  END AS pickup_segment,
  AVG(delivery_time) AS avg_delivery_time
FROM fct_delivery_routes
WHERE route_date >= '2024-10-01' AND route_date < '2025-01-01'
  AND pickup_count >= 2
GROUP BY 
  CASE 
    WHEN pickup_count = 2 THEN 'Only_two'
    WHEN pickup_count >= 3 THEN 'Three_or_more'
  END;

